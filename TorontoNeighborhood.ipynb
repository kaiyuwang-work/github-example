{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # library to handle data in a vectorized manner\n",
    "\n",
    "import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import json # library to handle JSON files\n",
    "\n",
    "#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "import folium # map rendering library\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml.html import parse\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from pandas.io.parsers import TextParser\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_link='https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\n",
    "doc = parse(urlopen(wikipedia_link))\n",
    "tables = doc.xpath('//table')\n",
    "\n",
    "def _unpack(row, kind='td'):\n",
    "    elts = row.xpath('.//%s' %kind)\n",
    "    return [val.text_content() for val in elts]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_options_data(table):\n",
    "    rows = table.xpath('.//tr')\n",
    "    header = _unpack(rows[0], kind='th')\n",
    "    data = [_unpack(r) for r in rows[1:]]\n",
    "    return TextParser(data, names=header).get_chunk()\n",
    "\n",
    "content = parse_options_data(tables[0])\n",
    "content.index = range(len(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove undefined Borough rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create content2\n",
    "content2 = content.copy()\n",
    "content2 =content2.drop(content2.index, inplace=False)\n",
    "\n",
    "# filter not assigned Borough\n",
    "index = 0\n",
    "content2.columns = ['Postcode', 'Borough', 'Neighbourhood']\n",
    "for i in content['Borough']:\n",
    "    if i != \"Not assigned\":\n",
    "#         print(content.loc[index])\n",
    "        st = content[\"Neighbourhood\\n\"][index]\n",
    "        pos=st.rfind('\\n')\n",
    "        st=st[:pos]\n",
    "#         print(\"st: \"+st)\n",
    "        series = pd.Series({\"Postcode\":content[\"Postcode\"][index],\"Borough\":content[\"Borough\"][index],\"Neighbourhood\":st})\n",
    "        content2 = content2.append(series,ignore_index=True)\n",
    "    index += 1\n",
    "    \n",
    "#refill undefined neighborhood    \n",
    "for i in range(len(content2[\"Neighbourhood\"])):\n",
    "    if content2['Neighbourhood'][i] == \"Not assigned\":\n",
    "        content2['Neighbourhood'][i] = content2['Borough'][i] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Neighbourhood data upon Postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create content2\n",
    "content3 = content2.copy()\n",
    "final = content2.copy()\n",
    "final =final.drop(final.index, inplace=False)\n",
    "\n",
    "#Merge neighbor data\n",
    "x = len(content3[\"Postcode\"])-1 #set loop length - 1\n",
    "temp = content3[\"Neighbourhood\"][0] # Initialize temp\n",
    "\n",
    "for i in range(x):\n",
    "#     print(\"when i equals \" + str(i) +\" \"+str(i != len(content3[\"Postcode\"])))\n",
    "    if (content3[\"Postcode\"][i+1] == content3[\"Postcode\"][i]):\n",
    "#         print(\"temp in IF = \"+temp)\n",
    "        temp = temp+','+content3[\"Neighbourhood\"][i+1] #merge neighbourhood info while postcodes are same\n",
    "    else :\n",
    "#         print(\"temp in ELSE = \"+temp)\n",
    "        series = pd.Series({\"Postcode\":content3[\"Postcode\"][i],\"Borough\":content3[\"Borough\"][i],\"Neighbourhood\":temp}) #write to new Series when the next line is different\n",
    "        final = final.append(series,ignore_index=True)\n",
    "        temp=content3[\"Neighbourhood\"][i+1] \n",
    "\n",
    "if content3[\"Postcode\"][x] == content3[\"Postcode\"][x-1]: #check if the last one is the same as previous ones\n",
    "    temp = temp+','+content3[\"Neighbourhood\"][x]\n",
    "    series = pd.Series({\"Postcode\":content3[\"Postcode\"][x-1],\"Borough\":content3[\"Borough\"][x-1],\"Neighbourhood\":temp})\n",
    "    final = final.append(series,ignore_index=True)\n",
    "else :\n",
    "    series = pd.Series({\"Postcode\":content3[\"Postcode\"][x],\"Borough\":content3[\"Borough\"][x],\"Neighbourhood\":content3[\"Neighbourhood\"][x]})\n",
    "    final = final.append(series,ignore_index=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape of pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 3)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape #shape of pre-processed data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
